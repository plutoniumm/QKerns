<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="utf-8" />
	<link rel="icon" href="./favicon.png" />
	<meta name="viewport" content="width=device-width" />

	<link rel="stylesheet" href="https://api.nukes.in/css/global.css">
	<link rel="stylesheet" href="https://api.nukes.in/css/keyframes.css">

	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css" crossorigin="anonymous">

	<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js" crossorigin="anonymous"></script>
	<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js"
		crossorigin="anonymous"></script>

	<meta http-equiv="content-security-policy" content="">
		<link href="./_app/immutable/assets/_layout-674ce39a.css" rel="stylesheet">
		<link href="./_app/immutable/assets/_page-b0284470.css" rel="stylesheet">
		<link rel="modulepreload" href="./_app/immutable/start-f384fab1.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/index-4da46a33.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/singletons-0506d623.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/paths-24bb4e9c.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/preload-helper-41c905a7.js">
		<link rel="modulepreload" href="./_app/immutable/components/pages/_layout.svelte-485fd4bc.js">
		<link rel="modulepreload" href="./_app/immutable/modules/pages/_layout.js-9cbb603b.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/_layout-da46b06b.js">
		<link rel="modulepreload" href="./_app/immutable/components/pages/mechanism/_page.svelte-d4639751.js">
</head>

<body data-sveltekit-preload-data="hover">
	<div style="display: contents">


<main class="svelte-1cfsoo"><nav class="fade-right svelte-1cfsoo"><div id="logo" class="ƒ ∆-ct mx-a" style="padding: 20px 0 10px 0;"><img src="/qiskit.svg" alt="logo" height="36px" width="36px" style="margin-right: 5px;">
      <div class="fw4" style="font-size:24px;line-height:36px;align-self:center">new qkerns()
      </div></div>
    <hr class="w-50 o-25">
    <ul class="p20 svelte-1cfsoo"><li class="svelte-1cfsoo"><a href="/">Home</a></li>
      <li class="svelte-1cfsoo"><a href="/visualisations">Visualisations</a></li>
      <li class="svelte-1cfsoo"><a href="/mechanism">Mechanism</a></li></ul></nav>
  <div class="p20 fade content svelte-1cfsoo"><h1 class="w-100 mx-a">Kernel Functions</h1>
<section class="svelte-1qyrz6f"><h2>Regression</h2>
  <p>Our objective first is to find the best linear predictor for the response
    variable $Y$ given the covariates $X$. We will assume that the response
    variable $Y$ is a linear combination of the covariates $X$ and derive a
    weight matrix $w$ such that <br>
    $$ Y = w^T X $$ <br>
    We do this simply by defining the loss function as the sum of squared errors
    and minimizing it with respect to $w$. We can write this as <br>
    $$ J(w) = \min_w \sum_{i=1}^n (y_i - w^T x_i)^2 $$ <br>
    Solving this for $w$ gives us <br>
    $$ w = (X^T X)^{-1} X^T Y $$
  </p></section>
<section class="svelte-1qyrz6f"><h2>Non Linearity</h2>
  <p>We can extend this to non linear mappings for $X$ by introducing a function
    $\phi$ such that $X \rightarrow \phi(X)$. We can then write the desired
    predictor as <br>
    $$ Y = w^T \phi(X) $$ <br>
    We can then also write the weight matrix as <br>
    $$ w^* = (\phi^T \phi)^{-1} \phi^T Y $$ <br>
    Let us introduce a regularization term $\lambda$ such that the weight matrix
    is <br>
    $$ w = (\phi^T \phi + \lambda I)^{-1} \phi^T Y $$ <br>
    The logic behind adding a regularization term is that we want to penalise the
    slope of the line. This is because we want to avoid overfitting. Adding bias
    results in a lower variance which makes the outputs less sensitive to the inputs.
    The parameter $\lambda$ is what controls the amount of bias we want to add
    <br>
    We additionally notice that in order to calculate the weight matrix, we need
    also calculate $\phi^T \phi$ which is an $n \times n$ matrix. This is computationally
    expensive and we can instead use a &#39;kernel trick&#39; to avoid this. Before we do
    that, in the next section we will first set up the necessary background for the
    kernel trick.
  </p></section>
<details class="p5 rx20 svelte-1qyrz6f" style="border:1px solid #ccc;"><summary><h2 class="d-ib m5">Restructuring the Weight Matrix</h2>
    <div class="mx-a"><b>Result:</b> <br>
      $ w^* = (\phi^T \phi + \lambda I)^{-1} \phi^T Y $ → <br> $ w^*
      = \phi^T (\phi \phi^T + \lambda&#39; I)^{-1} Y $
    </div></summary>
  <p>Let us now define the new loss function along with a regularization term <br>
    $$ J(w) = \min_w \sum_{i=1}^n (y_i - w^T \phi(x_i))^2 + \frac{\lambda}2
    ||w||^2 $$ <br>
    We can now solve for $w$ and get <br>
    $$ w^* = \frac1{\lambda} \sum_{i=1}^n (y_i - w^T \phi(x_i))
    \phi(x_i) $$ <br>
    For sake of simplicity let us define a variable $\alpha$ such that <br>
    $$ \alpha = \frac1{\lambda} \sum_{i=1}^n (y_i - w^T
    \phi(x_i)) $$ <br>
    We can now write the weight matrix as <br>
    $$ w^* = \sum_{i=1}^n \alpha_i \phi(x_i) = \phi^T \alpha $$ <br>
    Let us now substitute this into the loss function and get <br>
    $$ J(\alpha) = (y - \phi \alpha)^T (y - \phi \alpha) + \frac{\lambda}2
    w^T w $$ <br>
    expanding and simplifying this will give us <br>
    $$ J(\alpha) = y^T y - y^T \phi \phi^T \alpha - \alpha^T \phi^T y + \alpha^T
    \phi^T \phi \alpha + \frac{\lambda}2 w^T w $$ <br>

    We can see that $\phi \phi^T$ is a repeated term. Let us define this new
    matrix as $K$ such that $$ K = \phi \phi^T = \begin{bmatrix}
    \phi(x_1)^T \phi(x_1) &amp; \phi(x_1)^T \phi(x_2) &amp; \cdots &amp; \phi(x_1)^T \phi(x_n)
    \\ \phi(x_2)^T \phi(x_1) &amp; \phi(x_2)^T \phi(x_2) &amp; \cdots &amp; \phi(x_2)^T \phi(x_n)
    \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ \phi(x_n)^T \phi(x_1) &amp; \phi(x_n)^T \phi(x_2)
    &amp; \cdots &amp; \phi(x_n)^T \phi(x_n) \end{bmatrix} $$ <br>

    This matrix has two very important properties. First, it is symmetric and
    second, it is positive semi-definite. (This also means it is invertible
    which $\phi^T \phi$ MAY NOT). We can substitute all $\phi \phi^T$ with $K$
    and also $K$ with $K^T$ and get <br>
    $$ J(\alpha) = y^T y - 2 y^T K \alpha + \alpha^T K^2 \alpha + \frac{\lambda}2
    \alpha^T K \alpha $$ <br>
    Seeting the derivative of this with respect to $\alpha$ to zero and solving for
    $\alpha$ gives us (along with $K = \phi \phi^T$) <br>
    $$ \alpha* = (K + \frac{\lambda}2 I)^-1 y $$ or $$ \alpha* = (K
    + \lambda&#39; I)^-1 y $$ <br>
    We have achieved in this section effectively converting one equation to another
    as follows <br>
    $$ w^* = (\phi^T \phi + \lambda I)^-1 \phi^T Y $$ into <br>
    $$ w^* = \phi^T (K + \lambda&#39; I)^-1 Y $$ <br>
    By the looks of it we may not have done anything, but as we will see in the next
    section, this step will reduce the computation time by a lot.
  </p></details>
<section class="svelte-1qyrz6f"><h2>Mercer&#39;s Theorem</h2>
  <p>A symmetric positive semi-definite function $K(x, y)$ can be expressed as an
    inner product of two vectors $\phi(x)$ and $\phi(y)$ such that <br>
    $$ K(x, y) = \langle \phi(x), \phi(y) \rangle $$ for some function $\phi$ iff
    $K(x,y)$ is positive semi-definite i.e <br>
    $$ \int K(x, y) g(x) g(y) dx dy \geq 0 \forall g $$ or equivalently <br>
    $$ \begin{bmatrix} K(x_1, x_1) &amp; K(x_1, x_2) &amp; \cdots \\ K(x_2, x_1) &amp; \ddots
    &amp; \\ \vdots &amp; &amp; \ddots \end{bmatrix} $$ <br>
    is positive semi-definite for any collection ${x_1, x_2, \cdots}$
    <br></p></section>
<section class="svelte-1qyrz6f"><h2>The Kernel Trick</h2>
  <p>What Mercer&#39;s Theorem lets us do is rewrite every term in the Kernel matrix
    $K$ as only a function of its base features $$ K = \phi \phi^T = \begin{bmatrix}
    \phi(x_1)^T \phi(x_1) &amp; \phi(x_1)^T \phi(x_2) &amp; \cdots &amp; \phi(x_1)^T \phi(x_n)
    \\ \phi(x_2)^T \phi(x_1) &amp; \phi(x_2)^T \phi(x_2) &amp; \cdots &amp; \phi(x_2)^T \phi(x_n)
    \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ \phi(x_n)^T \phi(x_1) &amp; \phi(x_n)^T \phi(x_2)
    &amp; \cdots &amp; \phi(x_n)^T \phi(x_n) \end{bmatrix}
    $$ <br></p>
  <ul class="d-ib"><li>First: $K$ is symmetric</li>
    <li>Second: $K$ is positive semi-definite (This also means it is invertible
      which $\phi^T \phi$ MAY NOT)
    </li></ul>
  <p>hi</p></section>

</div>
</main>


		<script type="module" data-sveltekit-hydrate="5aav4q">
			import { start } from "./_app/immutable/start-f384fab1.js";

			start({
				assets: "",
				env: {},
				target: document.querySelector('[data-sveltekit-hydrate="5aav4q"]').parentNode,
				version: "1676860281219",
				hydrate: {
					node_ids: [0, 3],
					data: [null,null],
					form: null,
					error: null
				}
			});
		</script>
	</div>

	<script type="module">
		import renderMathInElement from "https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.mjs";

		setTimeout( () => {
			renderMathInElement( document.querySelector( '.content' ), {
				output: 'html',
				delimiters: [
					{ left: '$$', right: '$$', display: true },
					{ left: '$', right: '$', display: false }
				],
				throwOnError: false
			} );
		}, 1000 );
	</script>
	<style>
		@import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800;900&display=swap');

		body {
			background: #f5f5f7;
			font-family: 'Inter', sans-serif;
		}

		.katex {
			font-size: 1em !important;
		}
	</style>
</body>

</html>